# MVGBench
A comprehensive benchmark suite for multi-view generation models

[Project Page](https://virtualhumans.mpi-inf.mpg.de/MVGBench/) | [ArXiv paper](https://virtualhumans.mpi-inf.mpg.de/MVGBench/MVGBench.pdf)

## Installation

The environment installation is similar to [gaussian-splatting](https://github.com/graphdeco-inria/gaussian-splatting) environment. 

```shell
conda create -n mvgbench python=3.10 -y
conda activate mvgbench
pip install trimesh numpy==1.24.3 opencv-python==4.10.0.84 plyfile tqdm pillow==10.2.0 scikit-learn scikit-image lpips 
pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu118

# compile 3dgs dependencies 
cd submodules
git clone --recursive https://github.com/ashawkey/diff-gaussian-rasterization
pip install ./diff-gaussian-rasterization
pip install ./simple-knn
```

## Evaluation 
### 3D consistency metric 

Download example data from [this link](), these are the multi-view images generated by [SV3D](https://arxiv.org/abs/2403.12008) 
and [SyncDreamer](https://arxiv.org/abs/2309.03453). 

<details>
<summary><strong>Synthetic rendering as input</strong></summary>
For input images generated by rendering, where one can accurately control the camera setup. 

Run 3dgs fitting
```shell
# 3DGS fitting 
python run_mvfit.py "example/syncdreamer+mvdfusion-v16-elev030-amb1.0+i000+sel11v4_*/*" --white_background

# evaluation
python eval/eval_consistency.py \
  --name_odd output/consistency/syncdreamer+mvdfusion-v16-elev030-amb1.0+i000+sel11v4_odd \
  --name_even output/consistency/syncdreamer+mvdfusion-v16-elev030-amb1.0+i000+sel11v4_even
```

</details>

<details>
<summary><strong>Real images as input</strong></summary>
For input images from real data, where the camera poses are unknown. 

Similar to synthetic images, we first need to do 3DGS fitting and then compute self consistency. 
We additionally need to perform an alignment on the optimized 3DGS to avoid biased metrics. 
The alignment takes output of one method as reference and aligns all others w.r.t one 3DGS fitting. 

```shell
# 3DGS fitting 
python run_mvfit.py "example/*co3d2seq*/*" --white_background

python eval/align_3dgs.py --folder_tgt output/consistency/sv3dp+co3d2seq-sv3d-v21-manual+i000_even \
  --folder_src output/consistency/syncdreamer+co3d2seq-mvdfusion-v16-manual+i000_even

# Re-render with the alignment parameters, with the --normalize_gs flag 
python render.py --normalize_gs --quiet --resolution 256 -m "output/consistency/syncdreamer+co3d2seq-mvdfusion-v16-manual+i000_*/*"

# Evaluate
python eval/eval_consistency.py \
  --name_odd output/consistency/syncdreamer+co3d2seq-mvdfusion-v16-manual+i000_odd \
  --name_even output/consistency/syncdreamer+co3d2seq-mvdfusion-v16-manual+i000_even \
  --test_name align-icp # use new rendering to evaluate 
```

</details>

Object FID (oFID)

it can be used as an additional option passed to the consistency script 

### VLM based image quality and semantic consistency 
This evaluation requires `4x48GB` (or equivalent) GPU memory to run. 

First, download InternVL2.5 checkpoint and install additional dependencies:
```shell
# InternVL2.5 checkpoint 
huggingface-cli download --resume-download --local-dir-use-symlinks False OpenGVLab/InternVL2_5-78B --local-dir pretrained/InternVL2_5-78B

# additional dependencies
pip install accelerate einops transformers==4.37.2
```
Second, download VLM annotations for all four datasets from [this link]() and the unzip `unzip file.zip -d examples`

Run evaluation with: 
```shell
python eval/eval_vlm.py --name_even output/consistency/syncdreamer+mvdfusion-v16-elev030-amb1.0+i000+sel11v4_even
```
It will print out summary of the four VLM metrics: IQ-vlm, class, color and style semantic consistency. 


## Citation
```
@inproceedings{xie2025MVGBench,
  title={MVGBench: a Comprehensive Benchmark for Multi-view Generation Models},
  author={Xianghui Xie and Chuhang Zou and  Meher Gitika Karumuri and Jan Eric Lenssen and Gerard Pons-Moll},
  year={2025},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}
```